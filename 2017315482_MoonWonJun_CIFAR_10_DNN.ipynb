{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2017315482_MoonWonJun_CIFAR-10_DNN3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "DpC4kVjN1vwB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "58766852-567a-42f9-e9e6-1f6bd50e7699"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import torchvision\n",
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data.sampler import SubsetRandomSampler"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MSaASizy9-Nq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transform_train = transforms.Compose(\n",
        "    [\n",
        "     transforms.Resize(32,32), \n",
        "     transforms.RandomHorizontalFlip(),  ##좌우 대칭 Data Augmentation 이외에는 성능이 떨어짐.\n",
        "     #transforms.RandomRotation((-5,5)),\n",
        "     transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))\n",
        "     ]\n",
        ")\n",
        "\n",
        "transform_valid = transforms.Compose(\n",
        "    [transforms.Resize(32,32),\n",
        "     transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))\n",
        "     ]\n",
        ")\n",
        "transform_test = transforms.Compose(\n",
        "    [transforms.Resize(32,32),\n",
        "     transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))\n",
        "     ]\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LsqVFvn23d8z",
        "colab_type": "code",
        "outputId": "5a2baac7-bf54-4a2b-d0c5-e2121c2b097b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "trainset = torchvision.datasets.CIFAR10(root='./data', \n",
        "                                        train=True,\n",
        "                                        download=True, \n",
        "                                        transform=transform_train)\n",
        "\n",
        "validset = torchvision.datasets.CIFAR10(root='./data', \n",
        "                                        train=True,\n",
        "                                        download=True, \n",
        "                                        transform=transform_valid)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', \n",
        "                                       train=False,\n",
        "                                       download=True, \n",
        "                                       transform=transform_test)\n",
        "\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2IR1aNF35Lc",
        "colab_type": "code",
        "outputId": "b5340601-f816-4b06-d3aa-2bcf1bca1481",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "len(trainset)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "njLJFViVAff3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "index = list(range(len(trainset)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7SSMnirAhaF",
        "colab_type": "code",
        "outputId": "9062619c-0c18-413e-931c-ce23e8e953e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "len(testset)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MbYgVzHpE5t3",
        "colab_type": "text"
      },
      "source": [
        "### TrainSet ValidationSet 9 : 1 비율로 split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jWY1el3HAoLu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tr_len = int(len(trainset) * 0.9)\n",
        "va_len = int(len(trainset) * 0.1)\n",
        "# train_data, valid_data = torch.utils.data.random_split(trainset,[tr_len, va_len])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hiflN7jWALl3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.random.seed(4321)\n",
        "np.random.shuffle(index)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0scJclYvBJY6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_index, valid_index = index[:tr_len], index[-va_len:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wRs7i9JRdlZ4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_sampler = SubsetRandomSampler(train_index)\n",
        "valid_sampler = SubsetRandomSampler(valid_index)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zEI637zudnGg",
        "colab_type": "text"
      },
      "source": [
        "### Train, Valid index를 뽑아준다음 DataLoader를 만들어준다. 이때, shuffle option은 SubsetRandomSampler와 같이 쓰이지 못하므로 제외시켜준다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JDF-L0iYdnw7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(\n",
        "    trainset, batch_size=4, sampler=train_sampler, num_workers=0\n",
        ")\n",
        "\n",
        "valid_loader = torch.utils.data.DataLoader(\n",
        "    validset, batch_size=4, sampler=valid_sampler, num_workers=2\n",
        ")\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    testset, batch_size=4, shuffle=False, num_workers=2\n",
        ")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MhYzSMI4ihks",
        "colab_type": "text"
      },
      "source": [
        "### Model Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22-l89mLQN5r",
        "colab_type": "code",
        "outputId": "dcb34427-0d87-4c14-8a31-f59a2755fa84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "!pip install torchsummary"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.6/dist-packages (1.5.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDcRCi4hQRDt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchsummary import summary"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j6CvtbkrE_Q3",
        "colab_type": "text"
      },
      "source": [
        "### Input 3x32x32 = 3072"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SC_DhAsL5Wfa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DNN(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super(DNN, self).__init__()\n",
        "    self.input_size = 3072\n",
        "    self.hidden_size = 1024\n",
        "    self.linear1 = torch.nn.Linear(self.input_size, self.hidden_size)\n",
        "    self.relu1 = torch.nn.ReLU()\n",
        "    # self.linear2 = torch.nn.Linear(self.hidden_size, 512)\n",
        "    # self.relu2 = torch.nn.ReLU()\n",
        "    self.linear3 = torch.nn.Linear(1024, 256)\n",
        "    self.relu3 = torch.nn.ReLU()\n",
        "    # self.linear4 = torch.nn.Linear(256, 128)\n",
        "    # self.relu4 = torch.nn.ReLU()\n",
        "    self.linear5 = torch.nn.Linear(256, 64)\n",
        "    self.relu5 = torch.nn.ReLU()\n",
        "    self.linear6 = torch.nn.Linear(64, 32)\n",
        "    self.relu6 = torch.nn.ReLU()\n",
        "    self.linear7 = torch.nn.Linear(32, 10) #class label 10개.\n",
        "\n",
        "  def forward(self, input_tensor):\n",
        "    input_tensor = input_tensor.view(-1,3072)\n",
        "    linear1 = self.linear1(input_tensor)\n",
        "    relu1 = self.relu1(linear1)\n",
        "    # linear2 = self.linear2(relu1)\n",
        "    # relu2 = self.relu2(linear2)\n",
        "    linear3 = self.linear3(relu1)\n",
        "    relu3 = self.relu3(linear3)\n",
        "    # linear4 = self.linear4(relu3)\n",
        "    # relu4 = self.relu4(linear4)\n",
        "    linear5 = self.linear5(relu3)\n",
        "    relu5 = self.relu5(linear5)\n",
        "    linear6 = self.linear6(relu5)\n",
        "    relu6 = self.relu6(linear6)\n",
        "    linear7 = self.linear7(relu6)\n",
        "    return linear7\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mP-TG3PYilca",
        "colab_type": "text"
      },
      "source": [
        "### Params\n",
        "### Transforms Preprocessing, Parameter Tuning 진행을 해보았지만 \n",
        "### 단순 MLP 만으로는 한계가 있음. 56% 최대."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_Tmdg8f2Brf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = DNN()\n",
        "learning_rate = 0.0005\n",
        "epochs = 14 \n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr= learning_rate, momentum=0.7)\n",
        "#모멘텀은 신경망의 학습 안정성과 속도를 높여 학습이 잘 하려고 사용. \n",
        "#모멘텀 은 다음과 같이 가중치를 갱신할 때 델타 규칙에 모멘텀을 추가로 더함.\n",
        "#모멘텀을 사용하면 가중치 값이 바로 바뀌지 않고 어느 정도 일정한 방향을 유지하면서 움직이게 됨. \n",
        "#또한 가속도처럼 같은 방향으로 더 많이 변화시켜 학습속도를 높여줘 빠른 학습을 하게 됨.\n",
        "\n",
        "#같은 방향으로 연속으로 가중치가 변화되었으므로 가중치가 더 크게 변경. \n",
        "#역으로, 첫 번째와 두 번째의 가중치 방향이 반대이면 변화량이 감소합니다. \n",
        "#쉽게 플러스(+) 부호에서 마이너스(-) 부호로 변경되므로 변화량이 적어진다."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FwkJA3rQdssh",
        "colab_type": "text"
      },
      "source": [
        "### Keras 의 model.summary 와 같은 기능으로 Output Shape과 파라미터를 볼 수 있다. \n",
        "### 단, shape을 argument로 넣어줘야 한다. 디버깅 용도로 이용."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lcstDmQC_zbW",
        "colab_type": "code",
        "outputId": "14c77ead-467f-4574-c81a-7a8cf8029c86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        }
      },
      "source": [
        "summary(model,(3,32,32))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Linear-1                 [-1, 1024]       3,146,752\n",
            "              ReLU-2                 [-1, 1024]               0\n",
            "            Linear-3                  [-1, 256]         262,400\n",
            "              ReLU-4                  [-1, 256]               0\n",
            "            Linear-5                   [-1, 64]          16,448\n",
            "              ReLU-6                   [-1, 64]               0\n",
            "            Linear-7                   [-1, 32]           2,080\n",
            "              ReLU-8                   [-1, 32]               0\n",
            "            Linear-9                   [-1, 10]             330\n",
            "================================================================\n",
            "Total params: 3,428,010\n",
            "Trainable params: 3,428,010\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 0.02\n",
            "Params size (MB): 13.08\n",
            "Estimated Total Size (MB): 13.11\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z2TBiXJvioat",
        "colab_type": "text"
      },
      "source": [
        "### Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "je9-Y35e4mJN",
        "colab_type": "code",
        "outputId": "e5ffb0cf-c61f-409a-e374-f03ee62e3eb8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for epoch in range(epochs):\n",
        "  model.train()\n",
        "  running_loss = 0.0\n",
        "  for i, (data, target) in enumerate(train_loader):\n",
        "    data, target = Variable(data), Variable(target)\n",
        "    optimizer.zero_grad()\n",
        "    # 역전파 단계 전에, Optimizer 객체를 사용하여 (모델의 학습 가능한 가중치인)\n",
        "    # 갱신할 변수들에 대한 모든 변화도를 0으로 만듬. 이렇게 하는 이유는\n",
        "    # 기본적으로 .backward()를 호출할 때마다 변화도가 버퍼(buffer)에 (덮어쓰지 않고)\n",
        "    # 누적되기 때문.\n",
        "    output = model(data)\n",
        "    loss = criterion(output, target)\n",
        "    loss.backward()   #역전파 단계: 모델의 매개변수에 대한 손실의 변화도를 계산\n",
        "    optimizer.step()  # Optimizer의 step 함수를 호출하면 매개변수가 갱신\n",
        "    running_loss += loss.item()\n",
        "    if i % 4000 == 3999:    # print every 2000 mini-batches\n",
        "      print('Training Loss : [%d, %5d] loss: %.3f' %\n",
        "        (epoch + 1, i + 1, running_loss / 4000))\n",
        "      running_loss = 0.0\n",
        "\n",
        "  #Validation \n",
        "  correct = 0\n",
        "  total = 0\n",
        "  for i, (data, target) in enumerate(valid_loader, 0):\n",
        "    data, target = Variable(data), Variable(target)\n",
        "    output = model(data)\n",
        "    _, predicted = torch.max(output.data, 1) # 아래 test의 max와 다른 max 이용 방법.\n",
        "    #torch.max 함수는 텐서의 최대 값이 들어있는 index를 반환함.\n",
        "    #test에서 설명하지만 max는 value, index를 return. _ 에는 따라서 value가 들어가있음.\n",
        "    total += target.size(0)\n",
        "    correct += (predicted == target).sum().item()\n",
        "  print('#### [%d iteration] Validation Accuracy : [%d %%] ' % (epoch+1, 100*correct/total))  \n",
        "  if epoch % 1 == 0 or epoch % 9 == 0:\n",
        "    print('Train loss at {}/{} is {}'.format(epoch+1, epochs, loss.item()))\n",
        "  \n"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Loss : [1,  4000] loss: 2.299\n",
            "Training Loss : [1,  8000] loss: 2.231\n",
            "#### [1 iteration] Validation Accuracy : [28 %] \n",
            "Train loss at 1/14 is 1.8312065601348877\n",
            "Training Loss : [2,  4000] loss: 1.903\n",
            "Training Loss : [2,  8000] loss: 1.812\n",
            "#### [2 iteration] Validation Accuracy : [38 %] \n",
            "Train loss at 2/14 is 1.939528465270996\n",
            "Training Loss : [3,  4000] loss: 1.673\n",
            "Training Loss : [3,  8000] loss: 1.626\n",
            "#### [3 iteration] Validation Accuracy : [43 %] \n",
            "Train loss at 3/14 is 1.6026771068572998\n",
            "Training Loss : [4,  4000] loss: 1.531\n",
            "Training Loss : [4,  8000] loss: 1.514\n",
            "#### [4 iteration] Validation Accuracy : [47 %] \n",
            "Train loss at 4/14 is 2.1144301891326904\n",
            "Training Loss : [5,  4000] loss: 1.451\n",
            "Training Loss : [5,  8000] loss: 1.415\n",
            "#### [5 iteration] Validation Accuracy : [50 %] \n",
            "Train loss at 5/14 is 1.1451464891433716\n",
            "Training Loss : [6,  4000] loss: 1.371\n",
            "Training Loss : [6,  8000] loss: 1.354\n",
            "#### [6 iteration] Validation Accuracy : [52 %] \n",
            "Train loss at 6/14 is 1.0423595905303955\n",
            "Training Loss : [7,  4000] loss: 1.310\n",
            "Training Loss : [7,  8000] loss: 1.312\n",
            "#### [7 iteration] Validation Accuracy : [53 %] \n",
            "Train loss at 7/14 is 0.8086845278739929\n",
            "Training Loss : [8,  4000] loss: 1.266\n",
            "Training Loss : [8,  8000] loss: 1.256\n",
            "#### [8 iteration] Validation Accuracy : [54 %] \n",
            "Train loss at 8/14 is 0.9662836194038391\n",
            "Training Loss : [9,  4000] loss: 1.205\n",
            "Training Loss : [9,  8000] loss: 1.219\n",
            "#### [9 iteration] Validation Accuracy : [53 %] \n",
            "Train loss at 9/14 is 1.2362887859344482\n",
            "Training Loss : [10,  4000] loss: 1.170\n",
            "Training Loss : [10,  8000] loss: 1.181\n",
            "#### [10 iteration] Validation Accuracy : [55 %] \n",
            "Train loss at 10/14 is 2.5968401432037354\n",
            "Training Loss : [11,  4000] loss: 1.137\n",
            "Training Loss : [11,  8000] loss: 1.141\n",
            "#### [11 iteration] Validation Accuracy : [56 %] \n",
            "Train loss at 11/14 is 0.8038561344146729\n",
            "Training Loss : [12,  4000] loss: 1.082\n",
            "Training Loss : [12,  8000] loss: 1.104\n",
            "#### [12 iteration] Validation Accuracy : [55 %] \n",
            "Train loss at 12/14 is 1.1516751050949097\n",
            "Training Loss : [13,  4000] loss: 1.053\n",
            "Training Loss : [13,  8000] loss: 1.067\n",
            "#### [13 iteration] Validation Accuracy : [56 %] \n",
            "Train loss at 13/14 is 0.9594370126724243\n",
            "Training Loss : [14,  4000] loss: 1.045\n",
            "Training Loss : [14,  8000] loss: 1.017\n",
            "#### [14 iteration] Validation Accuracy : [57 %] \n",
            "Train loss at 14/14 is 1.556480884552002\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ONeNG2UmiwB8",
        "colab_type": "text"
      },
      "source": [
        "### Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oL4Tm4zr63iN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test():\n",
        "  model.eval()\n",
        "  test_loss = 0\n",
        "  correct = 0\n",
        "  for data, target in test_loader:\n",
        "    data,target = Variable(data, volatile=True), Variable(target)\n",
        "    output = model(data)\n",
        "    #print(output)\n",
        "    test_loss += criterion(output,target).item()#.data[0]\n",
        "    pred = output.data.max(1, keepdim=True)[1] #max값은 value, index를 반환한다.\n",
        "    #따라서. [1] 은 index 즉 어느 것이 확률이 제일 큰지 label 반환\n",
        "    #max 안의 1 은 어느 방향으로 큰 값을 찾을지 결정.\n",
        "    correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
        "    #pred.eq는 안에 값과 같은지 검사.\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "  print('Test  {}/{},  Test Accuracy : {}'.format(correct,len(test_loader.dataset), 100. * correct / len(test_loader.dataset)))   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pl0n8CNOizYW",
        "colab_type": "text"
      },
      "source": [
        "### Result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RwXo_DCpOttb",
        "colab_type": "code",
        "outputId": "55857ba4-ac4b-48cd-f611-c89c167a9e30",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "test()"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Test  5639/10000,  Test Accuracy : 56.38999938964844\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_QDYX1epO8-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vud6yqqEK_WF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}